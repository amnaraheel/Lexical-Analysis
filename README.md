# Lexical-Analysis
Python has a built-in package called “re”, which can be used to work with Regular Expressions. The tokenize function takes a string of code as input and returns a list of tokens, where each token is a tuple consisting of the token type (as determined by the regular expression pattern) and the token value (the actual string that matched the pattern). The regular expression in this example consists of several named groups, each of which corresponds to a particular token type. The “finditer” method of the re module is used to iterate over all the matches in the code string, and for each match, the “lastgroup” attribute is used to determine the token type, and the group method is used to get the token value.
